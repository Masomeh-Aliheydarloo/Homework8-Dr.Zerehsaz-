{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HomeWork8-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfceRYoET8mJ"
      },
      "source": [
        "HomeWork8.part 1\n",
        "\n",
        "Author: Masomeh Aliheydarloo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv_30uZxqQey"
      },
      "source": [
        "## Loading the data and other imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loClM54MqqWl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3M4Hz87PLbB"
      },
      "source": [
        "digits = load_digits(return_X_y =True)\n",
        "X=digits[0]\n",
        "y=digits[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEk_RY9c4Tsp",
        "outputId": "b0bb69f9-f366-437f-fec6-5921fbe0e2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape   #we have 64 features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEGrJytq4Vym",
        "outputId": "b9b43cf3-97b9-4cb5-e4c4-3c706e0dd954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7nrP4-952WU",
        "outputId": "c637e31b-e7e4-48ea-9a48-9037a1900be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsToYkNrP0Jq",
        "outputId": "0aadf64f-32d7-44eb-f4ea-67bc37b5e28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(X[63,:].reshape(8,8),cmap='gray') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f970aab0748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhOCCeeMvcx"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxpw7u6XwjtO"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-e1dsB1L-gH"
      },
      "source": [
        "# 1)a,b:Crossvalidate the hyperparameters ùëê, Œ≥, degree of polynomial ùëë and three kernels (linear, rbf and poly) and find the best setting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faqpzCr3wdYO"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZoJ2UmBWotr"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"svm\", SVC())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-XXMyGsXrZT"
      },
      "source": [
        "#Create hyperparameters space\n",
        "param_grid = [{\n",
        "'svm__kernel': ['linear','rbf','poly'],\n",
        "'svm__C': np.arange(0.01,11,1),\n",
        "'svm__gamma': np.arange(0.001,0.01,0.001),\n",
        "'svm__degree': [1, 2, 3, 4]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh8QRYIoWrN8",
        "outputId": "88acdad4-e28b-4f29-d3eb-aab8b0b49043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnqpDyvSXLxM",
        "outputId": "e1738b6b-3012-482b-bab9-17f0c904beb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "grid_svm = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=10)\n",
        "grid_svm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('scaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('svm',\n",
              "                                        SVC(C=1.0, break_ties=False,\n",
              "                                            cache_size=200, class_weight=None,\n",
              "                                            coef0=0.0,\n",
              "                                            decision_function_shape='ovr',\n",
              "                                            degree=3, gamma='scale',\n",
              "                                            kernel='rbf', max_iter=-1,\n",
              "                                            probability=False,\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0...\n",
              "             param_grid=[{'svm__C': array([1.000e-02, 1.010e+00, 2.010e+00, 3.010e+00, 4.010e+00, 5.010e+00,\n",
              "       6.010e+00, 7.010e+00, 8.010e+00, 9.010e+00, 1.001e+01]),\n",
              "                          'svm__degree': [1, 2, 3, 4],\n",
              "                          'svm__gamma': array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]),\n",
              "                          'svm__kernel': ['linear', 'rbf', 'poly']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX5eCu6pM96t"
      },
      "source": [
        "### Finding the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "638qKq-xYgTg",
        "outputId": "3cd5bfb6-5d02-4c86-aaca-f658ac90e38b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Best parameters: {}\".format(grid_svm.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'svm__C': 9.01, 'svm__degree': 2, 'svm__gamma': 0.009000000000000001, 'svm__kernel': 'poly'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLiR1yxDu7b6"
      },
      "source": [
        "### Evaluating cross validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZxAlkMru-sM",
        "outputId": "186f4f7a-bba7-4aa6-f1c3-627880dd2b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_svm.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_svm.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation accuracy: 0.99\n",
            "Test set score: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtw_JDAw5ue",
        "outputId": "08e3b4bd-d01c-432c-c64d-5c74c44c52fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        }
      },
      "source": [
        "import pandas as pd\n",
        "# convert to DataFrame\n",
        "results = pd.DataFrame(grid_svm.cv_results_)\n",
        "# show the first 5 rows\n",
        "display(results.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1148</th>\n",
              "      <th>1149</th>\n",
              "      <th>1150</th>\n",
              "      <th>1151</th>\n",
              "      <th>1152</th>\n",
              "      <th>1153</th>\n",
              "      <th>1154</th>\n",
              "      <th>1155</th>\n",
              "      <th>1156</th>\n",
              "      <th>1157</th>\n",
              "      <th>1158</th>\n",
              "      <th>1159</th>\n",
              "      <th>1160</th>\n",
              "      <th>1161</th>\n",
              "      <th>1162</th>\n",
              "      <th>1163</th>\n",
              "      <th>1164</th>\n",
              "      <th>1165</th>\n",
              "      <th>1166</th>\n",
              "      <th>1167</th>\n",
              "      <th>1168</th>\n",
              "      <th>1169</th>\n",
              "      <th>1170</th>\n",
              "      <th>1171</th>\n",
              "      <th>1172</th>\n",
              "      <th>1173</th>\n",
              "      <th>1174</th>\n",
              "      <th>1175</th>\n",
              "      <th>1176</th>\n",
              "      <th>1177</th>\n",
              "      <th>1178</th>\n",
              "      <th>1179</th>\n",
              "      <th>1180</th>\n",
              "      <th>1181</th>\n",
              "      <th>1182</th>\n",
              "      <th>1183</th>\n",
              "      <th>1184</th>\n",
              "      <th>1185</th>\n",
              "      <th>1186</th>\n",
              "      <th>1187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean_fit_time</th>\n",
              "      <td>0.0561727</td>\n",
              "      <td>0.399772</td>\n",
              "      <td>0.257054</td>\n",
              "      <td>0.0562116</td>\n",
              "      <td>0.400213</td>\n",
              "      <td>0.255828</td>\n",
              "      <td>0.0555783</td>\n",
              "      <td>0.398617</td>\n",
              "      <td>0.256307</td>\n",
              "      <td>0.0548735</td>\n",
              "      <td>0.399603</td>\n",
              "      <td>0.254539</td>\n",
              "      <td>0.0540719</td>\n",
              "      <td>0.399742</td>\n",
              "      <td>0.257087</td>\n",
              "      <td>0.0550196</td>\n",
              "      <td>0.39936</td>\n",
              "      <td>0.256501</td>\n",
              "      <td>0.0541569</td>\n",
              "      <td>0.401666</td>\n",
              "      <td>0.256147</td>\n",
              "      <td>0.0546273</td>\n",
              "      <td>0.396375</td>\n",
              "      <td>0.255611</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.397724</td>\n",
              "      <td>0.25507</td>\n",
              "      <td>0.0547411</td>\n",
              "      <td>0.398792</td>\n",
              "      <td>0.260272</td>\n",
              "      <td>0.0543241</td>\n",
              "      <td>0.401479</td>\n",
              "      <td>0.258726</td>\n",
              "      <td>0.0542976</td>\n",
              "      <td>0.39779</td>\n",
              "      <td>0.257739</td>\n",
              "      <td>0.0559357</td>\n",
              "      <td>0.398148</td>\n",
              "      <td>0.257601</td>\n",
              "      <td>0.054325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.172408</td>\n",
              "      <td>0.0430879</td>\n",
              "      <td>0.0792204</td>\n",
              "      <td>0.146774</td>\n",
              "      <td>0.0420426</td>\n",
              "      <td>0.0805649</td>\n",
              "      <td>0.130216</td>\n",
              "      <td>0.042816</td>\n",
              "      <td>0.085942</td>\n",
              "      <td>0.119864</td>\n",
              "      <td>0.0422436</td>\n",
              "      <td>0.0893385</td>\n",
              "      <td>0.113726</td>\n",
              "      <td>0.043056</td>\n",
              "      <td>0.0752125</td>\n",
              "      <td>0.267449</td>\n",
              "      <td>0.0423818</td>\n",
              "      <td>0.0692878</td>\n",
              "      <td>0.26478</td>\n",
              "      <td>0.0421711</td>\n",
              "      <td>0.06961</td>\n",
              "      <td>0.26297</td>\n",
              "      <td>0.0425251</td>\n",
              "      <td>0.0708108</td>\n",
              "      <td>0.257469</td>\n",
              "      <td>0.0445818</td>\n",
              "      <td>0.0761323</td>\n",
              "      <td>0.24677</td>\n",
              "      <td>0.0428645</td>\n",
              "      <td>0.0787669</td>\n",
              "      <td>0.231788</td>\n",
              "      <td>0.0429285</td>\n",
              "      <td>0.0807437</td>\n",
              "      <td>0.209531</td>\n",
              "      <td>0.0435469</td>\n",
              "      <td>0.0843016</td>\n",
              "      <td>0.191777</td>\n",
              "      <td>0.0432267</td>\n",
              "      <td>0.0888876</td>\n",
              "      <td>0.173975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_fit_time</th>\n",
              "      <td>0.00391615</td>\n",
              "      <td>0.00539902</td>\n",
              "      <td>0.00494142</td>\n",
              "      <td>0.00176063</td>\n",
              "      <td>0.00570735</td>\n",
              "      <td>0.00372602</td>\n",
              "      <td>0.00368213</td>\n",
              "      <td>0.00428692</td>\n",
              "      <td>0.00364716</td>\n",
              "      <td>0.00150614</td>\n",
              "      <td>0.00406109</td>\n",
              "      <td>0.00199945</td>\n",
              "      <td>0.000737963</td>\n",
              "      <td>0.00299188</td>\n",
              "      <td>0.00555913</td>\n",
              "      <td>0.00101874</td>\n",
              "      <td>0.00359405</td>\n",
              "      <td>0.00244109</td>\n",
              "      <td>0.00081513</td>\n",
              "      <td>0.00429542</td>\n",
              "      <td>0.00232847</td>\n",
              "      <td>0.00168365</td>\n",
              "      <td>0.00175702</td>\n",
              "      <td>0.00582142</td>\n",
              "      <td>0.000506612</td>\n",
              "      <td>0.00348137</td>\n",
              "      <td>0.00283169</td>\n",
              "      <td>0.00150697</td>\n",
              "      <td>0.00505429</td>\n",
              "      <td>0.00440346</td>\n",
              "      <td>0.00061166</td>\n",
              "      <td>0.00409886</td>\n",
              "      <td>0.00372372</td>\n",
              "      <td>0.00108787</td>\n",
              "      <td>0.00346518</td>\n",
              "      <td>0.00437418</td>\n",
              "      <td>0.00294302</td>\n",
              "      <td>0.00282003</td>\n",
              "      <td>0.00239218</td>\n",
              "      <td>0.000559813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00373771</td>\n",
              "      <td>0.00153907</td>\n",
              "      <td>0.00397879</td>\n",
              "      <td>0.00305745</td>\n",
              "      <td>0.00129259</td>\n",
              "      <td>0.00119528</td>\n",
              "      <td>0.00282494</td>\n",
              "      <td>0.00116201</td>\n",
              "      <td>0.00208363</td>\n",
              "      <td>0.00200204</td>\n",
              "      <td>0.00123311</td>\n",
              "      <td>0.00281421</td>\n",
              "      <td>0.00280451</td>\n",
              "      <td>0.00262318</td>\n",
              "      <td>0.00325998</td>\n",
              "      <td>0.00556553</td>\n",
              "      <td>0.00189108</td>\n",
              "      <td>0.00216836</td>\n",
              "      <td>0.00425543</td>\n",
              "      <td>0.000991059</td>\n",
              "      <td>0.00131641</td>\n",
              "      <td>0.00574804</td>\n",
              "      <td>0.00136546</td>\n",
              "      <td>0.00159929</td>\n",
              "      <td>0.00543478</td>\n",
              "      <td>0.00138332</td>\n",
              "      <td>0.00159238</td>\n",
              "      <td>0.00269927</td>\n",
              "      <td>0.00164673</td>\n",
              "      <td>0.00333935</td>\n",
              "      <td>0.00533578</td>\n",
              "      <td>0.00175702</td>\n",
              "      <td>0.0013145</td>\n",
              "      <td>0.0017147</td>\n",
              "      <td>0.00190313</td>\n",
              "      <td>0.00144775</td>\n",
              "      <td>0.00357391</td>\n",
              "      <td>0.00159846</td>\n",
              "      <td>0.00257371</td>\n",
              "      <td>0.00268943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_score_time</th>\n",
              "      <td>0.00866284</td>\n",
              "      <td>0.0250184</td>\n",
              "      <td>0.0165103</td>\n",
              "      <td>0.00885739</td>\n",
              "      <td>0.0243483</td>\n",
              "      <td>0.0166181</td>\n",
              "      <td>0.00852191</td>\n",
              "      <td>0.0248685</td>\n",
              "      <td>0.0165112</td>\n",
              "      <td>0.0087615</td>\n",
              "      <td>0.0251109</td>\n",
              "      <td>0.0169522</td>\n",
              "      <td>0.00857356</td>\n",
              "      <td>0.0244889</td>\n",
              "      <td>0.0167706</td>\n",
              "      <td>0.00895715</td>\n",
              "      <td>0.0247996</td>\n",
              "      <td>0.0165726</td>\n",
              "      <td>0.00849469</td>\n",
              "      <td>0.0246631</td>\n",
              "      <td>0.0166756</td>\n",
              "      <td>0.00867295</td>\n",
              "      <td>0.0243336</td>\n",
              "      <td>0.0165715</td>\n",
              "      <td>0.00867546</td>\n",
              "      <td>0.0243788</td>\n",
              "      <td>0.0165304</td>\n",
              "      <td>0.00853207</td>\n",
              "      <td>0.0245759</td>\n",
              "      <td>0.0168569</td>\n",
              "      <td>0.00862591</td>\n",
              "      <td>0.0253029</td>\n",
              "      <td>0.0170025</td>\n",
              "      <td>0.00878379</td>\n",
              "      <td>0.024502</td>\n",
              "      <td>0.0166778</td>\n",
              "      <td>0.00871549</td>\n",
              "      <td>0.0247219</td>\n",
              "      <td>0.0168501</td>\n",
              "      <td>0.00892305</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0137543</td>\n",
              "      <td>0.00585229</td>\n",
              "      <td>0.0108791</td>\n",
              "      <td>0.0121794</td>\n",
              "      <td>0.00565326</td>\n",
              "      <td>0.0110287</td>\n",
              "      <td>0.0109821</td>\n",
              "      <td>0.00579171</td>\n",
              "      <td>0.0115068</td>\n",
              "      <td>0.0101076</td>\n",
              "      <td>0.00584342</td>\n",
              "      <td>0.0118832</td>\n",
              "      <td>0.00947771</td>\n",
              "      <td>0.00578444</td>\n",
              "      <td>0.0113198</td>\n",
              "      <td>0.0174916</td>\n",
              "      <td>0.00559125</td>\n",
              "      <td>0.0103624</td>\n",
              "      <td>0.0177339</td>\n",
              "      <td>0.00568821</td>\n",
              "      <td>0.0100914</td>\n",
              "      <td>0.0171547</td>\n",
              "      <td>0.00570183</td>\n",
              "      <td>0.0102723</td>\n",
              "      <td>0.0165608</td>\n",
              "      <td>0.00585687</td>\n",
              "      <td>0.011304</td>\n",
              "      <td>0.0162071</td>\n",
              "      <td>0.00579245</td>\n",
              "      <td>0.0110358</td>\n",
              "      <td>0.0156665</td>\n",
              "      <td>0.00570025</td>\n",
              "      <td>0.0113472</td>\n",
              "      <td>0.0149314</td>\n",
              "      <td>0.00571084</td>\n",
              "      <td>0.0112994</td>\n",
              "      <td>0.0140834</td>\n",
              "      <td>0.00570121</td>\n",
              "      <td>0.0116063</td>\n",
              "      <td>0.0128753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_score_time</th>\n",
              "      <td>0.000148148</td>\n",
              "      <td>0.0012964</td>\n",
              "      <td>0.000166709</td>\n",
              "      <td>0.00028083</td>\n",
              "      <td>0.000240014</td>\n",
              "      <td>0.000196161</td>\n",
              "      <td>7.45171e-05</td>\n",
              "      <td>0.000731119</td>\n",
              "      <td>7.54143e-05</td>\n",
              "      <td>0.000325423</td>\n",
              "      <td>0.00146332</td>\n",
              "      <td>0.00147557</td>\n",
              "      <td>0.000241328</td>\n",
              "      <td>0.000381911</td>\n",
              "      <td>0.000915946</td>\n",
              "      <td>0.00103327</td>\n",
              "      <td>0.000782303</td>\n",
              "      <td>0.000203973</td>\n",
              "      <td>5.44726e-05</td>\n",
              "      <td>0.000227237</td>\n",
              "      <td>0.000375138</td>\n",
              "      <td>0.000215405</td>\n",
              "      <td>0.000225377</td>\n",
              "      <td>0.000336464</td>\n",
              "      <td>0.000350247</td>\n",
              "      <td>0.000238274</td>\n",
              "      <td>0.000178786</td>\n",
              "      <td>0.000121689</td>\n",
              "      <td>0.000437618</td>\n",
              "      <td>0.000294847</td>\n",
              "      <td>0.000152828</td>\n",
              "      <td>0.00243978</td>\n",
              "      <td>0.00039143</td>\n",
              "      <td>0.000780222</td>\n",
              "      <td>0.000397461</td>\n",
              "      <td>0.000198407</td>\n",
              "      <td>0.000761721</td>\n",
              "      <td>0.000913229</td>\n",
              "      <td>0.00032495</td>\n",
              "      <td>0.00110914</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000481037</td>\n",
              "      <td>0.000383934</td>\n",
              "      <td>0.000375229</td>\n",
              "      <td>0.000443006</td>\n",
              "      <td>0.000156201</td>\n",
              "      <td>0.000195394</td>\n",
              "      <td>0.00025672</td>\n",
              "      <td>0.000307489</td>\n",
              "      <td>0.000531441</td>\n",
              "      <td>0.000391273</td>\n",
              "      <td>0.000448456</td>\n",
              "      <td>0.000300009</td>\n",
              "      <td>0.000340991</td>\n",
              "      <td>0.000324687</td>\n",
              "      <td>0.000171631</td>\n",
              "      <td>0.000573741</td>\n",
              "      <td>0.000117398</td>\n",
              "      <td>0.00027937</td>\n",
              "      <td>0.00123148</td>\n",
              "      <td>0.000237161</td>\n",
              "      <td>0.000284934</td>\n",
              "      <td>0.000775867</td>\n",
              "      <td>0.000175936</td>\n",
              "      <td>0.000265103</td>\n",
              "      <td>0.000167707</td>\n",
              "      <td>0.000329816</td>\n",
              "      <td>0.00112342</td>\n",
              "      <td>0.000297827</td>\n",
              "      <td>0.000317805</td>\n",
              "      <td>0.000476495</td>\n",
              "      <td>0.000488143</td>\n",
              "      <td>0.000244018</td>\n",
              "      <td>0.000288511</td>\n",
              "      <td>0.000478288</td>\n",
              "      <td>0.000159009</td>\n",
              "      <td>0.000198047</td>\n",
              "      <td>0.00089048</td>\n",
              "      <td>0.00023143</td>\n",
              "      <td>0.000221204</td>\n",
              "      <td>0.000598597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_svm__C</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>...</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_svm__degree</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_svm__gamma</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_svm__kernel</th>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>...</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "      <td>linear</td>\n",
              "      <td>rbf</td>\n",
              "      <td>poly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params</th>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>{'svm__C': 0.01, 'svm__degree': 2, 'svm__gamma...</td>\n",
              "      <td>...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 3, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "      <td>{'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split0_test_score</th>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.951389</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.145833</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.340278</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.548611</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.659722</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.743056</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.819444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split1_test_score</th>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.784722</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.881944</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.909722</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.930556</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.131944</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.201389</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.326389</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.548611</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.597222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.701389</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.763889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split2_test_score</th>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>...</td>\n",
              "      <td>0.8125</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.930556</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.951389</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.180556</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.486111</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.569444</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split3_test_score</th>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.138889</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.180556</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.284722</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.451389</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.576389</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>1</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split4_test_score</th>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895833</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.131944</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.340278</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.680556</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split5_test_score</th>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868056</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.923611</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.965278</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.319444</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.673611</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.826389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split6_test_score</th>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.104167</td>\n",
              "      <td>0.0972222</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.847222</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.902778</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>0.0972222</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.118056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.180556</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.215278</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.993056</td>\n",
              "      <td>0.763889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split7_test_score</th>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.13986</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.202797</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>...</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.916084</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.118881</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.118881</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.167832</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.496503</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.65035</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.86014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split8_test_score</th>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>...</td>\n",
              "      <td>0.874126</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.93007</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.13986</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.13986</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.20979</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.335664</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.594406</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.671329</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.979021</td>\n",
              "      <td>0.797203</td>\n",
              "      <td>0.986014</td>\n",
              "      <td>0.972028</td>\n",
              "      <td>0.86014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split9_test_score</th>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.895105</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.93007</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.937063</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.111888</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.0979021</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.104895</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.160839</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.321678</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.958042</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.72028</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.965035</td>\n",
              "      <td>0.811189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_score</th>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.10928</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.115574</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>0.106483</td>\n",
              "      <td>0.105789</td>\n",
              "      <td>0.97772</td>\n",
              "      <td>...</td>\n",
              "      <td>0.835116</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.981187</td>\n",
              "      <td>0.902598</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.98328</td>\n",
              "      <td>0.938092</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.983979</td>\n",
              "      <td>0.956177</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.983974</td>\n",
              "      <td>0.965215</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.981896</td>\n",
              "      <td>0.107178</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.981881</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.98397</td>\n",
              "      <td>0.132891</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.981187</td>\n",
              "      <td>0.188568</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.980488</td>\n",
              "      <td>0.320115</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.981187</td>\n",
              "      <td>0.536548</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.98328</td>\n",
              "      <td>0.635388</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.983979</td>\n",
              "      <td>0.734227</td>\n",
              "      <td>0.980502</td>\n",
              "      <td>0.983974</td>\n",
              "      <td>0.806619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_test_score</th>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0106385</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0292335</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>0.00353841</td>\n",
              "      <td>0.00448084</td>\n",
              "      <td>0.0102647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0408551</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0136346</td>\n",
              "      <td>0.0336881</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0125612</td>\n",
              "      <td>0.0278298</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0112644</td>\n",
              "      <td>0.0240758</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0116983</td>\n",
              "      <td>0.0172997</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.00838215</td>\n",
              "      <td>0.00482581</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0122007</td>\n",
              "      <td>0.0118194</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0125353</td>\n",
              "      <td>0.0201058</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0136346</td>\n",
              "      <td>0.0188688</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0139044</td>\n",
              "      <td>0.0186765</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0136346</td>\n",
              "      <td>0.044723</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0125612</td>\n",
              "      <td>0.0386111</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0112644</td>\n",
              "      <td>0.0387023</td>\n",
              "      <td>0.00815794</td>\n",
              "      <td>0.0116983</td>\n",
              "      <td>0.0383511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1098</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1084</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>740</td>\n",
              "      <td>1114</td>\n",
              "      <td>1172</td>\n",
              "      <td>740</td>\n",
              "      <td>...</td>\n",
              "      <td>947</td>\n",
              "      <td>263</td>\n",
              "      <td>226</td>\n",
              "      <td>926</td>\n",
              "      <td>263</td>\n",
              "      <td>61</td>\n",
              "      <td>907</td>\n",
              "      <td>263</td>\n",
              "      <td>7</td>\n",
              "      <td>885</td>\n",
              "      <td>263</td>\n",
              "      <td>29</td>\n",
              "      <td>861</td>\n",
              "      <td>263</td>\n",
              "      <td>156</td>\n",
              "      <td>1110</td>\n",
              "      <td>263</td>\n",
              "      <td>195</td>\n",
              "      <td>1086</td>\n",
              "      <td>263</td>\n",
              "      <td>45</td>\n",
              "      <td>1070</td>\n",
              "      <td>263</td>\n",
              "      <td>226</td>\n",
              "      <td>1046</td>\n",
              "      <td>263</td>\n",
              "      <td>659</td>\n",
              "      <td>1025</td>\n",
              "      <td>263</td>\n",
              "      <td>226</td>\n",
              "      <td>998</td>\n",
              "      <td>263</td>\n",
              "      <td>61</td>\n",
              "      <td>983</td>\n",
              "      <td>263</td>\n",
              "      <td>7</td>\n",
              "      <td>966</td>\n",
              "      <td>263</td>\n",
              "      <td>29</td>\n",
              "      <td>955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22 rows √ó 1188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                0     ...                                               1187\n",
              "mean_fit_time                                              0.0561727  ...                                           0.173975\n",
              "std_fit_time                                              0.00391615  ...                                         0.00268943\n",
              "mean_score_time                                           0.00866284  ...                                          0.0128753\n",
              "std_score_time                                           0.000148148  ...                                        0.000598597\n",
              "param_svm__C                                                    0.01  ...                                              10.01\n",
              "param_svm__degree                                                  1  ...                                                  4\n",
              "param_svm__gamma                                               0.001  ...                                              0.009\n",
              "param_svm__kernel                                             linear  ...                                               poly\n",
              "params             {'svm__C': 0.01, 'svm__degree': 1, 'svm__gamma...  ...  {'svm__C': 10.01, 'svm__degree': 4, 'svm__gamm...\n",
              "split0_test_score                                           0.979167  ...                                           0.819444\n",
              "split1_test_score                                           0.986111  ...                                           0.763889\n",
              "split2_test_score                                           0.979167  ...                                               0.75\n",
              "split3_test_score                                           0.986111  ...                                           0.777778\n",
              "split4_test_score                                           0.993056  ...                                           0.833333\n",
              "split5_test_score                                           0.965278  ...                                           0.826389\n",
              "split6_test_score                                           0.972222  ...                                           0.763889\n",
              "split7_test_score                                           0.972028  ...                                            0.86014\n",
              "split8_test_score                                           0.986014  ...                                            0.86014\n",
              "split9_test_score                                           0.958042  ...                                           0.811189\n",
              "mean_test_score                                              0.97772  ...                                           0.806619\n",
              "std_test_score                                             0.0102647  ...                                          0.0383511\n",
              "rank_test_score                                                  740  ...                                                955\n",
              "\n",
              "[22 rows x 1188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUrNElIneLFU"
      },
      "source": [
        "grid_svm.cv_results_['params']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XUZ9ox8dkq4",
        "outputId": "5ac58e4e-b557-44ab-d093-373fbaaa0e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "grid_svm.cv_results_['mean_test_score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9777195 , 0.1064831 , 0.1064831 , ..., 0.98050214, 0.98397436,\n",
              "       0.80661908])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZBF-Ho2hUKg"
      },
      "source": [
        "### Fitting the final model by the best parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOhrH3W-w0cu",
        "outputId": "678b25c4-12b3-46c4-8639-38a07de158b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "grid_svm.best_estimator_.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svm',\n",
              "                 SVC(C=9.01, break_ties=False, cache_size=200,\n",
              "                     class_weight=None, coef0=0.0,\n",
              "                     decision_function_shape='ovr', degree=2,\n",
              "                     gamma=0.009000000000000001, kernel='poly', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Go_Bjx2N5Se"
      },
      "source": [
        "###Evaluating Model Performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A09mTczrhu5y",
        "outputId": "50442941-88d4-4219-e049-b97937599859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(grid_svm.best_estimator_.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3IkjhkXh1vL",
        "outputId": "f87f2623-5620-42f0-8b1f-40e396662cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:','\\n',confusion_matrix(y_test,grid_svm.best_estimator_.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[36  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 35  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 38  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 35  0  1  0  0  1  0]\n",
            " [ 0  1  0  0 27  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 35  0  0  0  1]\n",
            " [ 0  0  0  0  0  0 37  0  0  0]\n",
            " [ 0  0  2  0  0  0  0 37  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 35  0]\n",
            " [ 0  0  0  1  0  1  0  2  0 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYFtYHsikIax",
        "outputId": "0c4645b6-5499-4d3e-dcad-12cb823f18ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "mat = confusion_matrix(y_test, grid_svm.best_estimator_.predict(X_test))\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False, \n",
        "            xticklabels=[0,1,2,3,4,5,6,7,8,9], yticklabels=[0,1,2,3,4,5,6,7,8,9])\n",
        "plt.xlabel('True Label')\n",
        "plt.ylabel('Predicted Label')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(91.68, 0.5, 'Predicted Label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQOoXjhR-1Fh"
      },
      "source": [
        "## Compute the mean and standard deviation of the best SVM model accuracy for 1000 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ixV963_-2Iz",
        "outputId": "d33f6981-8fb4-4f83-eeae-f49d86e1e21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_svm_acc = []\n",
        "\n",
        "for i in range(1000):\n",
        "    #split test and train data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    \n",
        "    #Fit model on training data\n",
        "    grid_svm.best_estimator_.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate model on test data\n",
        "    acc = grid_svm.best_estimator_.score(X_test, y_test)\n",
        "    test_svm_acc += [acc]\n",
        "\n",
        "print(\"Mean Test Accuracy:{:.2f}\".format(np.mean(test_svm_acc)))\n",
        "print(\"standard deviation Test Accuracy:{:.2f}\".format(np.std(test_svm_acc)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Test Accuracy:0.98\n",
            "standard deviation Test Accuracy:0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In0B9ygrO4zF"
      },
      "source": [
        "# 1)c:The parameter ccp_alpha (max_depth) in decision tree. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt3TYSZ2ip3D"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "990yfNofP7-F"
      },
      "source": [
        "#Create hyperparameters space\n",
        "param_grid_Dtree=[{'max_depth': range(1,10),\n",
        "                   'ccp_alpha':[0.0,0.01]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR7j_Iom31Ug",
        "outputId": "933c9f44-f779-4993-f0b4-9867e6ce33cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Scaled code\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"tree\", DecisionTreeClassifier())])\n",
        "param_grid_Dtree=[{'tree__max_depth': range(1,10)}]\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "grid_t = GridSearchCV(estimator=pipe, param_grid=param_grid_Dtree, cv=10)\n",
        "grid_t.fit(X_train, y_train)\n",
        "print(\"Best parameters: {}\".format(grid_t.best_params_))\n",
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_t.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_t.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'tree__max_depth': 9}\n",
            "Best cross-validation accuracy: 0.84\n",
            "Test set score: 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLqOObWEQy0O",
        "outputId": "341bca17-9b0e-43df-8dc4-36b27a8b927a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Create grid search\n",
        "grid_Dtree = GridSearchCV(estimator=tree, param_grid=param_grid_Dtree, scoring='accuracy',cv=10)\n",
        "grid_Dtree.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'ccp_alpha': [0.0, 0.01], 'max_depth': range(1, 10)}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB1UTIBwf4vk"
      },
      "source": [
        "### Finding the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prXmg49Hcc1E",
        "outputId": "47de6611-9507-4259-ad9f-e04750fc9b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Best parameters: {}\".format(grid_Dtree.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'ccp_alpha': 0.0, 'max_depth': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMrr7jrU3HvB"
      },
      "source": [
        "### Evaluating cross validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MjXt2hz3IC5",
        "outputId": "24c8aee3-c36e-4a5f-e08a-e954467c7b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_Dtree.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_Dtree.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation accuracy: 0.84\n",
            "Test set score: 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sijdbhIVhO_u"
      },
      "source": [
        "### Fitting the best parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpp6abHfVtn8",
        "outputId": "94c8bc39-565f-4737-8586-5e757cea2a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "grid_Dtree.best_estimator_.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNs0wfAghVYG"
      },
      "source": [
        "### Evaluating Model Performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxidEpOVdP4v",
        "outputId": "cf563d76-2b7e-43b0-a7be-c3b0baaaadcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(grid_Dtree.best_estimator_.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uokfyFq_dP40",
        "outputId": "b1279398-aab7-4a09-bde6-6062eacaa8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:','\\n',confusion_matrix(y_test,grid_Dtree.best_estimator_.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[30  0  0  0  0  0  1  0  0  0]\n",
            " [ 0 31  0  1  2  0  0  0  3  1]\n",
            " [ 1  0 33  0  0  1  0  0  0  1]\n",
            " [ 0  0  1 21  0  0  0  1  1  3]\n",
            " [ 1  1  0  1 31  1  0  2  0  0]\n",
            " [ 0  0  0  2  1 32  2  0  0  1]\n",
            " [ 1  0  0  0  1  1 32  0  0  0]\n",
            " [ 0  0  3  1  3  0  0 33  1  1]\n",
            " [ 0  1  2  3  0  0  0  0 27  1]\n",
            " [ 0  1  2  1  3  0  0  1  0 34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYlWwmAbHcBV"
      },
      "source": [
        "## Compute the mean and standard deviation of the best Decision Tree model accuracy for 1000 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOB-FXLHcBY",
        "outputId": "0c28ba95-2a2b-43f6-9bdd-5288ced8a857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_dt_acc = []\n",
        "\n",
        "for i in range(1000):\n",
        "    #split test and train data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    #Fit model on training data\n",
        "    grid_Dtree.best_estimator_.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate model on test data\n",
        "    acc = grid_Dtree.best_estimator_.score(X_test, y_test)\n",
        "    test_dt_acc += [acc]\n",
        "\n",
        "print(\"Mean Test Accuracy:{:.2f}\".format(np.mean(test_dt_acc)))\n",
        "print(\"standard deviation Test Accuracy:{:.2f}\".format(np.std(test_dt_acc)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Test Accuracy:0.85\n",
            "standard deviation Test Accuracy:0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7YstQW4htaq"
      },
      "source": [
        "# 1)d:Number of estimators for bagging. You can use the best tree obtained from part c as your base estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96sFdIFImOTm"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "bag=BaggingClassifier(base_estimator=tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7181WZzTm16D"
      },
      "source": [
        "#Create hyperparameters space\n",
        "param_grid_bag=[{'n_estimators': [10, 20, 30, 40, 50, 60, 70,80, 90, 100]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dz7AIK3m16I",
        "outputId": "a5fb359e-cb6e-44dd-d467-154fb70f5b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Create grid search\n",
        "grid_bag = GridSearchCV(estimator=bag, param_grid=param_grid_bag, scoring='accuracy',cv=10)\n",
        "grid_bag.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                               class_weight=None,\n",
              "                                                                               criterion='gini',\n",
              "                                                                               max_depth=None,\n",
              "                                                                               max_features=None,\n",
              "                                                                               max_leaf_nodes=None,\n",
              "                                                                               min_impurity_decrease=0.0,\n",
              "                                                                               min_impurity_split=None,\n",
              "                                                                               min_samples_leaf=1,\n",
              "                                                                               min_samples_split=2,\n",
              "                                                                               min_weight_fraction_leaf=0.0,\n",
              "                                                                               presort='deprecated',\n",
              "                                                                               random_s...\n",
              "                                                                               splitter='best'),\n",
              "                                         bootstrap=True,\n",
              "                                         bootstrap_features=False,\n",
              "                                         max_features=1.0, max_samples=1.0,\n",
              "                                         n_estimators=10, n_jobs=None,\n",
              "                                         oob_score=False, random_state=None,\n",
              "                                         verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
              "                                           100]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BFy2ljWpY57"
      },
      "source": [
        "### Finding the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRHan584mmvu",
        "outputId": "70209c16-91ef-4b14-fcc9-c06952b5e90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Best parameters: {}\".format(grid_bag.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_estimators': 70}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCHOTfVL5gaB"
      },
      "source": [
        "### Evaluating cross validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S0rY8Z25gt1",
        "outputId": "55aad9af-de6b-4949-89d9-e235531e1438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_bag.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_bag.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation accuracy: 0.95\n",
            "Test set score: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HVrt3TKmmv0"
      },
      "source": [
        "### Fitting the best parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhW_N_qfmmv1",
        "outputId": "ea81b271-9137-4391-bc9b-3c9ba0521f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "grid_bag.best_estimator_.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                        class_weight=None,\n",
              "                                                        criterion='gini',\n",
              "                                                        max_depth=None,\n",
              "                                                        max_features=None,\n",
              "                                                        max_leaf_nodes=None,\n",
              "                                                        min_impurity_decrease=0.0,\n",
              "                                                        min_impurity_split=None,\n",
              "                                                        min_samples_leaf=1,\n",
              "                                                        min_samples_split=2,\n",
              "                                                        min_weight_fraction_leaf=0.0,\n",
              "                                                        presort='deprecated',\n",
              "                                                        random_state=None,\n",
              "                                                        splitter='best'),\n",
              "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
              "                  max_samples=1.0, n_estimators=70, n_jobs=None,\n",
              "                  oob_score=False, random_state=None, verbose=0,\n",
              "                  warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhqAOrkuorzX"
      },
      "source": [
        "### Evaluating Model Performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waNXlyTxp83k",
        "outputId": "56c9122b-0490-47d6-84e6-954a3f729e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(grid_bag.best_estimator_.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R-ZZ-C7p83q",
        "outputId": "111f0b72-5437-40f2-9456-743116c1209c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:','\\n',confusion_matrix(y_test,grid_bag.best_estimator_.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[34  0  0  0  0  0  0  0  1  0]\n",
            " [ 0 36  0  0  0  0  0  0  1  0]\n",
            " [ 0  0 36  0  0  0  0  1  0  0]\n",
            " [ 0  0  0 38  0  1  0  0  0  2]\n",
            " [ 0  0  0  0 38  0  0  0  0  0]\n",
            " [ 0  0  0  1  1 32  0  0  0  0]\n",
            " [ 0  1  0  0  1  0 32  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 36  0  0]\n",
            " [ 0  1  1  0  0  0  0  0 26  0]\n",
            " [ 0  0  0  0  0  0  0  1  1 37]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbT0h6iYbaEy"
      },
      "source": [
        "### Compute the mean and standard deviation of the best Bagging model accuracy for 1000 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkWQJPN7baE0",
        "outputId": "ef04ad2a-3d0a-4223-afd6-0b0c005b4207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_bag_acc = []\n",
        "count=0\n",
        "\n",
        "for i in range(1000):\n",
        "    count=count+1\n",
        "    #split test and train data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    #Fit model on training data\n",
        "    grid_bag.best_estimator_.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate model on test data\n",
        "    acc = grid_bag.best_estimator_.score(X_test, y_test)\n",
        "    test_bag_acc += [acc]\n",
        "\n",
        "print(\"Mean Test Accuracy:{:.2f}\".format(np.mean(test_bag_acc)))\n",
        "print(\"standard deviation Test Accuracy:{:.2f}\".format(np.std(test_bag_acc)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Test Accuracy:0.95\n",
            "standard deviation Test Accuracy:0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t888nTE3qRMj"
      },
      "source": [
        "## 1)e: Number of estimators (M in slides) for boosting. You can use the best tree obtained from part c as your base estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxRC6OeRqpvu"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "boost = AdaBoostClassifier(base_estimator=tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um9lg-H0rkrh"
      },
      "source": [
        "#Create hyperparameters space\n",
        "param_grid_boost=[{'n_estimators': [10, 20, 30, 40, 50, 60, 70,80, 90, 100]}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rok84fZZrkrp",
        "outputId": "cb0fd24c-9a87-4e96-f70c-a4194252b029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Create grid search\n",
        "grid_boost = GridSearchCV(estimator=boost, param_grid=param_grid_boost, scoring='accuracy',cv=10)\n",
        "grid_boost.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                          base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                                                class_weight=None,\n",
              "                                                                                criterion='gini',\n",
              "                                                                                max_depth=None,\n",
              "                                                                                max_features=None,\n",
              "                                                                                max_leaf_nodes=None,\n",
              "                                                                                min_impurity_decrease=0.0,\n",
              "                                                                                min_impurity_split=None,\n",
              "                                                                                min_samples_leaf=1,\n",
              "                                                                                min_samples_split=2,\n",
              "                                                                                min_weight_fraction_leaf=0.0,\n",
              "                                                                                presort='deprecated',\n",
              "                                                                                random_state=None,\n",
              "                                                                                splitter='best'),\n",
              "                                          learning_rate=1.0, n_estimators=50,\n",
              "                                          random_state=None),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
              "                                           100]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s74whQhIrcHz"
      },
      "source": [
        "### Find the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhN0uXyssCqI",
        "outputId": "41f33adc-0b81-4f77-eb4d-c0381ca6244a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Best parameters: {}\".format(grid_boost.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'n_estimators': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK2r-ytP66L7"
      },
      "source": [
        "### Evaluating cross validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNv1bID66ZG",
        "outputId": "909f4400-eb15-498c-de4c-824c05f85884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_boost.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_boost.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation accuracy: 0.86\n",
            "Test set score: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIMkLWjgsHhZ"
      },
      "source": [
        "### Fitting the best parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK47odr7sHha",
        "outputId": "2a716226-317f-466b-f614-4baabbc99613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "grid_boost.best_estimator_.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best'),\n",
              "                   learning_rate=1.0, n_estimators=30, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgU6CDjStRpK"
      },
      "source": [
        "### Evaluating Model Performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNK0_A8LsiYb",
        "outputId": "6ea2c4e3-821c-453d-c0e0-2e6ab44c0202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(grid_boost.best_estimator_.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEU7IwBDsiYf",
        "outputId": "a7efd8bc-67d8-493d-a3c0-32c99546cd12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:','\\n',confusion_matrix(y_test,grid_boost.best_estimator_.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[28  0  0  0  0  2  0  0  0  0]\n",
            " [ 0 33  0  0  1  0  0  1  3  1]\n",
            " [ 0  0 40  0  0  0  0  1  3  1]\n",
            " [ 0  1  0 32  1  0  1  1  1  2]\n",
            " [ 0  0  0  0 35  1  1  1  1  0]\n",
            " [ 0  0  1  1  0 25  0  0  0  0]\n",
            " [ 2  0  0  0  0  0 29  1  0  0]\n",
            " [ 0  0  0  0  0  0  0 30  1  0]\n",
            " [ 2  1  1  1  0  2  0  1 27  4]\n",
            " [ 1  2  2  1  0  0  0  2  1 30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNfad-0cOFn"
      },
      "source": [
        "## Compute the mean and standard deviation of the best Boosting model accuracy for 1000 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddFyrtcXcOFp",
        "outputId": "84a102e6-a1c8-4d5f-d879-0941f8116dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_ada_acc = []\n",
        "\n",
        "for i in range(1000):\n",
        "    #split test and train data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    \n",
        "    #Fit model on training data\n",
        "    grid_boost.best_estimator_.fit(X_train, y_train)\n",
        "    \n",
        "    # Evaluate model on test data\n",
        "    acc = grid_boost.best_estimator_.score(X_test, y_test)\n",
        "    test_ada_acc += [acc]\n",
        "\n",
        "print(\"Mean Test Accuracy:{:.2f}\".format(np.mean(test_ada_acc)))\n",
        "print(\"standard deviation Test Accuracy:{:.2f}\".format(np.std(test_ada_acc)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Test Accuracy:0.85\n",
            "standard deviation Test Accuracy:0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY_ZOSCsSz2r"
      },
      "source": [
        "# 1)f: Number of estimators and max_depth and n_estimators in random forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CBNmA73temj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "randomf = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb0bq3NWOE45"
      },
      "source": [
        "#Create hyperparameters space\n",
        "param_grid_forest=[{'n_estimators': [10, 20, 30, 40, 50, 60, 70,80, 90, 100],\n",
        "                   'max_depth': range(1,10)}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jay_PXoOE5A",
        "outputId": "e0c523b5-7d51-4a8d-8ade-f5734bff973f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Create grid search\n",
        "grid_forest = GridSearchCV(estimator=randomf, param_grid=param_grid_forest, scoring='accuracy',cv=10)\n",
        "grid_forest.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'max_depth': range(1, 10),\n",
              "                          'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
              "                                           100]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RukaLfbSOMLu"
      },
      "source": [
        "### Finding the best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf-k9oxDQ7uM",
        "outputId": "e0461487-4ed7-4f8b-bc21-cd947a066fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Best parameters: {}\".format(grid_forest.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameters: {'max_depth': 9, 'n_estimators': 70}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "machTYJ-7sDU"
      },
      "source": [
        "### Evaluating cross validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xctwI5mU7sSl",
        "outputId": "581b00e4-ea70-400e-a361-93e60c1024b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_forest.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid_forest.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation accuracy: 0.98\n",
            "Test set score: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s37KmIJWRGN0"
      },
      "source": [
        "### Fitting the best parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcOFPTGERGN1",
        "outputId": "1d6f640f-32e7-4145-a242-966380cc05c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "grid_forest.best_estimator_.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=9, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=70,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5pj_0BUR2dO"
      },
      "source": [
        "### Evaluating Model Performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26qcL-_VSN6a",
        "outputId": "53a2fabf-82a1-46f7-de55-3d90bb73941e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test set score: {:.2f}\".format(grid_forest.best_estimator_.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYTf04rSSN6d",
        "outputId": "a05198b2-2c81-423c-e3c4-f03d9e374bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix:','\\n',confusion_matrix(y_test,grid_forest.best_estimator_.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[36  0  0  0  0  0  0  0  1  0]\n",
            " [ 0 37  0  0  0  1  0  0  0  0]\n",
            " [ 1  0 35  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 37  0  0  0  0  1  0]\n",
            " [ 0  0  0  0 30  0  0  1  0  0]\n",
            " [ 0  0  0  0  0 38  0  0  1  1]\n",
            " [ 0  0  0  0  0  0 41  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 36  0  1]\n",
            " [ 0  1  0  0  0  0  0  0 29  1]\n",
            " [ 0  0  0  0  0  0  0  0  1 29]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IFYLij2dUPF"
      },
      "source": [
        "## Compute the mean and standard deviation of the best Random Forest model accuracy for 1000 times:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP4M4f41dUPH",
        "outputId": "ad8cc03a-9384-4dcb-b372-a6a5151f2ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_randf_acc = []\n",
        "\n",
        "\n",
        "for i in range(1000):\n",
        "    #split test and train data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "    \n",
        "    #Fit model on training data\n",
        "    grid_forest.best_estimator_.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate model on test data\n",
        "    acc = grid_forest.best_estimator_.score(X_test, y_test)\n",
        "    test_randf_acc += [acc]\n",
        "\n",
        "print(\"Mean Test Accuracy:{:.2f}\".format(np.mean(test_randf_acc)))\n",
        "print(\"standard deviation Test Accuracy:{:.2f}\".format(np.std(test_randf_acc)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Test Accuracy:0.97\n",
            "standard deviation Test Accuracy:0.01\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}